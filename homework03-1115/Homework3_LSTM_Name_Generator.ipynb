{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://wiki.swarma.net/images/e/e7/集智AI学园首页左上角logo_2017.8.17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 火炬上的深度学习（下）第三节：神经网络莫扎特"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 课后作业：使用 LSTM 编写一个国际姓氏生成模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在火炬课程中，我们学习了使用 LSTM 来生成 MIDI 音乐。这节课我们使用类似的方法，再创建一个 LSTM 国际起名大师！\n",
    "\n",
    "完成后的模型能够像下面这样使用，指定一个国家名，模型即生成几个属于这个国家的姓氏。\n",
    "\n",
    "```\n",
    "> python generate.py Russian\n",
    "Rovakov    Uantov    Shavakov\n",
    "\n",
    "> python generate.py German\n",
    "Gerren    Ereng    Rosher\n",
    "\n",
    "> python generate.py Spanish\n",
    "Salla    Parer    Allan\n",
    "\n",
    "> python generate.py Chinese\n",
    "Chan    Hang    Iun\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 第一步当然是引入PyTorch及相关包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "这次的数据仍然是18个文本文件，每个文件以“国家名字”命名，文件中存储了大量这个国家的姓氏。\n",
    "\n",
    "在读取这些数据前，为了简化神经网络的输入参数规模，我们把各国各语言人名都转化成用26个英文字母来表示，下面就是转换的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "6a9d80df-1d38-4c41-849c-95e38da98cc7"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O'Neal\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "# all_letters 即课支持打印的字符+标点符号\n",
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "# Plus EOS marker\n",
    "n_letters = len(all_letters) + 1 \n",
    "EOS = n_letters - 1\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicode_to_ascii(\"O'Néàl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 `\"O'Néàl\"` 被转化成了以普通ASCII字符表示的 `O'Neal`。\n",
    "\n",
    "在上面的代码中，还要注意这么几个变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_letters:  abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'-\n",
      "n_letters:  59\n",
      "EOS:  58\n"
     ]
    }
   ],
   "source": [
    "# 姓氏中所有的可视字符\n",
    "print('all_letters: ', all_letters)\n",
    "# 所有字符的长度 +1 EOS结束符\n",
    "print('n_letters: ', n_letters)\n",
    "# 结束符，没有实质内容,索引从0开始，所以这是字符表长度减1\n",
    "print('EOS: ', EOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中 `all_letters` 包含了我们数据集中所有可能出现的字符，也就是“字符表”。\n",
    "`n_letters` 是字符表的长度，在本例中长度为59。`EOS` 的索引号为58，它在字符表中没有对应的字符，仅代表结束。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备好处理数据的方法，下面就可以放心的读取数据了。\n",
    "\n",
    "我们建立一个列表 `all_categories` 用于存储所有的国家名字。\n",
    "\n",
    "建立一个字典 `category_lines`，以读取的国名作为字典的索引，国名下存储对应国别的名字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# categories:  18 ['Arabic', 'Italian', 'Irish', 'Greek', 'Vietnamese', 'Spanish', 'Russian', 'Polish', 'Portuguese', 'Korean', 'German', 'Dutch', 'Chinese', 'Czech', 'Japanese', 'Scottish', 'French', 'English']\n",
      "\n",
      "# Russian names:  ['Ababko', 'Abaev', 'Abagyan', 'Abaidulin', 'Abaidullin', 'Abaimoff', 'Abaimov', 'Abakeliya', 'Abakovsky', 'Abakshin']\n"
     ]
    }
   ],
   "source": [
    "# 按行读取出文件中的名字，并返回包含所有名字的列表\n",
    "def read_lines(filename):\n",
    "    lines = open(filename).read().strip().split('\\n')\n",
    "    return [unicode_to_ascii(line) for line in lines]\n",
    "\n",
    "\n",
    "# category_lines是一个字典\n",
    "# 其中索引是国家名字，内容是从文件读取出的这个国家的所有名字\n",
    "category_lines = {}\n",
    "# all_categories是一个列表\n",
    "# 其中包含了所有的国家名字\n",
    "all_categories = []\n",
    "# 循环所有文件\n",
    "for filename in glob.glob('./names/*.txt'):\n",
    "    # 从文件名中切割出国家名字\n",
    "    category = filename.split('/')[-1].split('.')[0]\n",
    "    # 将国家名字添加到列表中\n",
    "    all_categories.append(category)\n",
    "    # 读取对应国别文件中所有的名字\n",
    "    lines = read_lines(filename)\n",
    "    # 将所有名字存储在字典中对应的国别下\n",
    "    category_lines[category] = lines\n",
    "\n",
    "# 共有的国别数\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "print('# categories: ', n_categories, all_categories)\n",
    "print()\n",
    "print('# Russian names: ', category_lines['Russian'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20074\n"
     ]
    }
   ],
   "source": [
    "# 再统计下手头共有多少条训练数据\n",
    "all_line_num = 0\n",
    "for key in category_lines:\n",
    "    all_line_num += len(category_lines[key])\n",
    "print(all_line_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们的数据准备好了，可以搭建神经网络了！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先建立一个可以随机选择数据对 `(category, line)` 的方法，以方便训练时调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Korean', 'Rhee')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def random_training_pair():\n",
    "    # 随机选择一个国别名\n",
    "    category = random.choice(all_categories)\n",
    "    # 读取这个国别名下的所有人名\n",
    "    line = random.choice(category_lines[category])\n",
    "    return category, line\n",
    "\n",
    "print(random_training_pair())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先处理国别，将国别名转化为索引。\n",
    "\n",
    "这个索引是要和姓氏一起传入神经网络模型的。我们这次编写的是根据“国名条件”生成“符合条件的姓氏”的 LSTM 模型。这种将“条件”和“符合条件的数据”合并一起作为训练输入数据的方法，在“条件模型”里非常流行。\n",
    "\n",
    "比如 条件GAN（Conditional GAN），在训练时是把数据标签拼接到数据图片中一起进行训练的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# 将名字所属的国家名转化为“独热向量”\n",
    "def make_category_input(category):\n",
    "    li = all_categories.index(category)\n",
    "    return  li\n",
    "\n",
    "print(make_category_input('Chinese'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "对于训练过程中的每一步，或者说对于训练数据中每个名字的每个字符来说，神经网络的输入是 `(category, current letter, hidden state)`，输出是 `(next letter, next hidden state)`。\n",
    "\n",
    "与在课程中讲的一样，神经网络还是依据“当前的字符”预测“下一个字符”。比如对于“Kasparov”这个名字，创建的（input, target）数据对是 (\"K\", \"a\"), (\"a\", \"s\"), (\"s\", \"p\"), (\"p\", \"a\"), (\"a\", \"r\"), (\"r\", \"o\"), (\"o\", \"v\"), (\"v\", \"EOS\")。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "cf311809-10bf-40f7-87e1-1952342f7f35"
    }
   },
   "outputs": [],
   "source": [
    "def make_chars_input(nameStr):\n",
    "    name_char_list = list(map(lambda x: all_letters.find(x), nameStr))\n",
    "    return name_char_list\n",
    "\n",
    "\n",
    "def make_target(nameStr):\n",
    "    target_char_list = list(map(lambda x: all_letters.find(x), nameStr[1:]))\n",
    "    target_char_list.append(n_letters - 1)# EOS\n",
    "    return target_char_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样为了训练时方便使用，我们建立一个 `random_training_set` 函数，以随机选择出数据集 `(category, line)` 并转化成训练需要的 Tensor： `(category, input, target) `。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_training_set():\n",
    "    # 随机选择数据集\n",
    "    category, line = random_training_pair()\n",
    "    #print(category, line)\n",
    "    # 转化成对应 Tensor\n",
    "    category_input = make_category_input(category)\n",
    "    line_input = make_chars_input(line)\n",
    "    #category_name_input = make_category_name_input(category, line)\n",
    "    line_target = make_target(line)\n",
    "    return category_input, line_input, line_target\n",
    "    #return category_name_input, line_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, [26, 14, 3, 7, 0], [14, 3, 7, 0, 58])\n"
     ]
    }
   ],
   "source": [
    "print(random_training_set())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4ff5f52a-2523-47f0-beba-f6c29d412e5f"
    }
   },
   "source": [
    "# 搭建神经网络\n",
    "\n",
    "这次使用的 LSTM 神经网络整体结构上与课上讲的生成音乐的模型非常相似，不过有一点请注意一下。\n",
    "\n",
    "我们要把国别和国别对应的姓氏一同输入到神经网络中，这样 LSTM 模型才能分别学习到每个国家姓氏的特色，从而生成不同国家不同特色的姓氏。\n",
    "\n",
    "那国别数据与姓氏数据应该如何拼接哪？应该在嵌入前拼接，还是在嵌入后再进行拼接哪？嵌入后的维度与 hidden_size 有怎样的关系哪？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要参考课上的模型，将这个模型补充完整。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 一个手动实现的LSTM模型，\n",
    "\n",
    "class LSTMNetwork(nn.Module):\n",
    "    def __init__(self, category_size, name_size, hidden_size, output_size, num_layers = 1):\n",
    "        super(LSTMNetwork, self).__init__()\n",
    "        self.category_size=category_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers =num_layers\n",
    "        self.name_size=name_size\n",
    "        # 进行嵌入\n",
    "        self.embedding=nn.Embedding(category_size+name_size,hidden_size)\n",
    "        \n",
    "        # 隐含层内部的相互链接\n",
    "        self.lstm=nn.LSTM(hidden_size,hidden_size,num_layers,batch_first=True)\n",
    "        self.fc=nn.Linear(hidden_size,output_size)\n",
    "        # 输出层\n",
    "        self.softmax=nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        # 先分别进行embedding层的计算\n",
    "        embedded=self.embedding(input)\n",
    "        #embedded=embedded.view(input.data.size()[0],1, self.hidden_size)\n",
    "        # 从输入到隐含层的计算\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        \n",
    "        # output的尺寸：batch_size, len_seq, hidden_size\n",
    "        output = output[:,-1,:]\n",
    "        # 全连接层\n",
    "        output=self.fc(output)\n",
    "\n",
    "        # output的尺寸：batch_size, output_size\n",
    "        # softmax函数\n",
    "        output=self.softmax(output)\n",
    "        \n",
    "        return output, hidden\n",
    " \n",
    "    def initHidden(self):\n",
    "        # 对隐含单元的初始化\n",
    "        # 注意尺寸是： layer_size, batch_size, hidden_size\n",
    "        # 对隐单元的初始化\n",
    "        # 对引单元输出的初始化，全0.\n",
    "        # 注意hidden和cell的维度都是layers,batch_size,hidden_size\n",
    "        hidden = Variable(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
    "        # 对隐单元内部的状态cell的初始化，全0\n",
    "        cell = Variable(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
    "        return (hidden, cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与之前处理得分类问题不同，在分类问题中只有最后的输出被使用。而在当前的 **生成** 姓氏的任务中，神经网络在每一步都会做预测，所以我们需要在每一步计算损失值。\n",
    "\n",
    "PyTorch 非常易用，它允许我们只是简单的把每一步计算的损失加起来，在遍历完一个姓氏后，再进行反向传播。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要将训练函数补充完整，或者编写自己的训练函数。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义训练函数，在这个函数里，我们可以随机选择一条训练数据，遍历每个字符进行训练,指的是每一个姓氏的损失\n",
    "def train_LSTM():\n",
    "    # 初始化 隐藏层、梯度清零、损失清零\n",
    "    hidden=lstm.initHidden()\n",
    "    optimizer.zero_grad()\n",
    "    loss=0\n",
    "    \n",
    "    # 随机选取一条训练数据\n",
    "    category_input, line_input, line_target = random_training_set()\n",
    "    # 处理国别数据\n",
    "    category_variable =Variable(torch.LongTensor(np.array([category_input])))\n",
    "    \n",
    "    \n",
    "    # 循环字符\n",
    "    for t in range(len(line_input)):\n",
    "        # 姓氏\n",
    "        name_variable = Variable(torch.LongTensor([line_input[t]]).unsqueeze(0))\n",
    "        x= torch.cat((category_variable,name_variable), )\n",
    "        # 目标\n",
    "        y_target=Variable(torch.LongTensor([line_target[t]]))\n",
    "        y=torch.cat((category_variable,y_target),)\n",
    "        # 传入模型\n",
    "        output,hidden=lstm(x,hidden)\n",
    "        # 累加损失\n",
    "        loss+= cost(output, y)\n",
    "        # 计算平均损失\n",
    "    loss = 1.0 * loss / len(line_input)\n",
    "    # 反向传播、更新梯度\n",
    "    loss.backward(retain_variables = True)\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们定义 `time_since` 函数，它可以打印出训练持续的时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def time_since(t):\n",
    "    now = time.time()\n",
    "    s = now - t\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**在下面你要定义损失函数、优化函数、实例化模型参数。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 10\n",
    "num_epoch = 3\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 实例化模型\n",
    "lstm = LSTMNetwork(n_categories, n_letters, hidden_size, n_letters, num_layers = 1)\n",
    "# 定义损失函数与优化方法\n",
    "optimizer = torch.optim.Adam(lstm.parameters(),lr=learning_rate)\n",
    "cost = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练的过程与我们前几节课一样，都是老套路啦！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kale/miniconda3/envs/kale/lib/python3.6/site-packages/torch/autograd/__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0轮，训练损失：0.57，训练进度：0.0%，（0m 1s）\n",
      "第0轮，训练损失：1.20，训练进度：4.98%，（0m 40s）\n",
      "第0轮，训练损失：1.20，训练进度：9.96%，（1m 19s）\n",
      "第0轮，训练损失：1.19，训练进度：14.94%，（1m 59s）\n",
      "第0轮，训练损失：1.19，训练进度：19.93%，（2m 38s）\n",
      "第0轮，训练损失：1.19，训练进度：24.91%，（3m 16s）\n",
      "第0轮，训练损失：1.19，训练进度：29.89%，（3m 54s）\n",
      "第1轮，训练损失：1.19，训练进度：33.33%，（4m 18s）\n",
      "第1轮，训练损失：1.19，训练进度：38.31%，（4m 56s）\n",
      "第1轮，训练损失：1.19，训练进度：43.3%，（5m 33s）\n",
      "第1轮，训练损失：1.19，训练进度：48.28%，（6m 11s）\n",
      "第1轮，训练损失：1.19，训练进度：53.26%，（6m 51s）\n",
      "第1轮，训练损失：1.19，训练进度：58.24%，（7m 31s）\n",
      "第1轮，训练损失：1.19，训练进度：63.22%，（8m 11s）\n",
      "第2轮，训练损失：1.19，训练进度：66.67%，（8m 38s）\n",
      "第2轮，训练损失：1.19，训练进度：71.65%，（9m 18s）\n",
      "第2轮，训练损失：1.19，训练进度：76.63%，（9m 58s）\n",
      "第2轮，训练损失：1.19，训练进度：81.61%，（10m 37s）\n",
      "第2轮，训练损失：1.19，训练进度：86.59%，（11m 14s）\n",
      "第2轮，训练损失：1.19，训练进度：91.57%，（11m 52s）\n",
      "第2轮，训练损失：1.19，训练进度：96.56%，（12m 29s）\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "records = []\n",
    "train_losses=[]\n",
    "# 开始训练循环\n",
    "for epoch in range(num_epoch):\n",
    "    # 按所有数据的行数随机循环\n",
    "    for i in range(all_line_num):\n",
    "        loss = train_LSTM()\n",
    "        train_losses.append(loss.data.numpy()[0])\n",
    "        \n",
    "        #每隔3000步，跑一次校验集，并打印结果\n",
    "        if i % 3000 == 0:\n",
    "            training_process = (all_line_num * epoch + i) / (all_line_num * num_epoch) * 100\n",
    "            training_process = '%.2f' % training_process\n",
    "            print('第{}轮，训练损失：{:.2f}，训练进度：{}%，（{}）'\\\n",
    "                .format(epoch, np.mean(train_losses), float(training_process), time_since(start)))\n",
    "            records.append([np.mean(train_losses)])str(str(str(str(str(str("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制观察损失曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们将训练过程中记录的损失绘制成一条曲线，观察下神经网络学习的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe0f00712b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHWBJREFUeJzt3X2UXHWd5/H3pzsdQkKSzkMLSICg4mgHIRv6gIzsENF1\nEx1ldNQFjDoMTg7nyDAcD7OTVY+6eMbDw854fGAmJ6MRGdngKjpGT5iMs4twVuWhYUN4jGQQpDGa\nTrpDMt3Efqjv/lG3Krerq7qr0327Ormf1zmdqrr3V3W/datSn7r3Vn1LEYGZmRlAU6MLMDOzmcOh\nYGZmZQ4FMzMrcyiYmVmZQ8HMzMocCmZmVuZQMDOzMoeCmZmVORTMzKxsVqMLmKilS5fG8uXLG12G\nmdkx5ZFHHtkXEW3jjTvmQmH58uV0dnY2ugwzs2OKpBfqGefdR2ZmVuZQMDOzMoeCmZmVORTMzKzM\noWBmZmWZhYKkzZL2SnqixvwPSdop6XFJP5N0Xla1mJlZfbLcUrgdWDPG/F8Cl0TEm4DPA5syrMXM\nzOqQ2fcUIuJ+ScvHmP+z1MUHgGVZ1TJZEcGdD/6K/oEhFsxpYf6cFhacOIsFc1pYcGILC+bMYsGJ\nLbQ0e2+cmR3bZsqX164G7qk1U9J6YD3AGWecMV01lb3Y8wqf/qeqe8FGOLGluWpYFINkVjlM5ieX\nF5SmJZfnzm5G0jTcIzOz6hoeCpLeSjEULq41JiI2kexe6ujoiGkqrWxf3+8AuO3KVaw6s5WDrwxx\n8PAgB18ZTE6HRp4/XDy/798HeG5fHwdfGeTQ4SGGCmOX3twkTjphVhIYR4Jk7uxmZjWLWU1iVnNT\n8bSp6ci0ZHpzk2hpTs9LxjYX57eUrt8sWpIxLc2ipbmJWU1Nxesmt9/SfOT2m5PlNSfLampycJkd\nrxoaCpLOBb4GrI2I/Y2sZSwH+gcAeHXrHE5deCKnLpz4bUQErwwOc+jwEIcOD3Lw8FA5LErTDh0u\nBkp6TFdvP4cHhxkqBEPDUTwtFBgeDgYLhfK06SQxIiyqhUdzk2gSNEk0SSg5X5ouVZ/f1HRkWmm+\nxhpfHnPkPMBwBIVCMBzBcCEoJKfDBcrnj0yL1DTKwXfkPql8n9L3Lx2SpTEiqTdZT6UtPyX/jJqf\nukx6bGpdF6ep4nLF/GTdNqtYT7OKbzJKtZXWfXPF+ebSY5I8LuXrp8Y1pR67atPH27gda+u32n1N\n39/R06dOU3p9JeeVrLfS9DxqWChIOgP4HvDhiPhFo+qoR0/fIACL580+6tuQxNzZs5g7exYnL5gz\nVaUBxcAZLpQCI8qBMVwIBodLwVFgcLgYLKUwGRwujJ6fGjeUjCvd9nChkJzGkdPhGtOTF9qIoJC8\nEBf/KJ9GaVrqhXogWV4wcv6Iy8ltRKRut1CaD0GM+s8+8gWAUdNmNTVxwqzii0Ihorx+Xhk8cj8L\nkb5/BQoFigGdWu+lOounyeNDsdYoXhhxuXKszSxHnj9HnjNHQnFkYJYCJT29SanAbTry5kWMfsMj\nisspv1FIv+mheHntOafwx+dne/g1s1CQtAVYDSyV1AV8FmgBiIiNwGeAJcDfJe8khiKiI6t6JqO3\nr7ilsGgSoZAlqbSLqNGV2FSKJCmOhEvF9NTYUjCWwmr0FlJUbCGNHlt6czGc3FZ5a6s8rRi6ldPH\nvhNjzToyM30z6auMnD5y/GQOv5XeUKTXTSEonk/d3+EYuXV5ZOyRNzalLcxCad2W37RUnxdRelNQ\nesNTuq0CMZxcFygk7xbSb4JefmXw6O90nbL89NEV48z/GPCxrJY/lXr7B5jVJOaf0PBDMJYj5V1P\no178xno19DsDmxx/hrIOvf0DtM6d7U8Gmdlxz6FQh56+ARbPa2l0GWZmmXMo1KG3f5DWuTPzeIKZ\n2VRyKNSht2+AxQ4FM8sBh0IdevsHZuwnj8zMppJDYRwRQW//oI8pmFkuOBTGcfDwEMOFYJF3H5lZ\nDjgUxlH+4ppDwcxywKEwjp6k79FkWlyYmR0rHArjKDXDa53rYwpmdvxzKIxjKprhmZkdKxwK45jp\nzfDMzKaSQ2EcPW6GZ2Y54lAYxwE3wzOzHHEojMPN8MwsTxwK4+jtG/R3FMwsNxwK4+jtH3AomFlu\nOBTG4WZ4ZpYnDoUxuBmemeWNQ2EMboZnZnnjUBiDm+GZWd44FMbgZnhmljeZhYKkzZL2Snqixvw3\nSPq5pN9JuiGrOibDLS7MLG+y3FK4HVgzxvwe4Drgf2RYw6T09heb4S1yh1Qzy4nMQiEi7qf4wl9r\n/t6IeBgYzKqGyfKWgpnljY8pjMHN8Mwsb46JUJC0XlKnpM7u7u5pW66b4ZlZ3hwToRARmyKiIyI6\n2trapm25boZnZnlzTIRCo7gZnpnlTWY7yyVtAVYDSyV1AZ8FWgAiYqOkU4BOYAFQkHQ90B4RB7Oq\naaJ6+gc4+1UnNboMM7Npk1koRMQV48z/DbAsq+VPhdIxBTOzvPDuoxoKBTfDM7P8cSjUcMjN8Mws\nhxwKNfT2uxmemeWPQ6EGN8MzszxyKNTgFhdmlkcOhRrcDM/M8sihUIO3FMwsjxwKNbgZnpnlkUOh\nht6+ARbNczM8M8sXh0INvf0DPp5gZrnjUKjBzfDMLI8cCjX09A/4OwpmljsOhRrcDM/M8sihUIWb\n4ZlZXjkUqnAzPDPLK4dCFe57ZGZ55VCowh1SzSyvHApVuMWFmeWVQ6GKniQUFntLwcxyxqFQxYGk\nQ2qrP31kZjnjUKjCzfDMLK8cClW4GZ6Z5VVmoSBps6S9kp6oMV+Svixpt6SdklZlVctE9fYP+HiC\nmeVSllsKtwNrxpi/Fjg7+VsP/H2GtUxIb98gre6QamY5lFkoRMT9QM8YQy4D7oiiB4BWSadmVc9E\nuBmemeVVI48pnAa8mLrclUxruNIxBTOzvDkmDjRLWi+pU1Jnd3d3pssqFIIDrwz6B3bMLJcaGQov\nAaenLi9Lpo0SEZsioiMiOtra2jItys3wzCzPGhkKW4GPJJ9CejPwckTsaWA9gJvhmVm+ZfbtLElb\ngNXAUkldwGeBFoCI2AhsA94J7Ab6gauyqmUi3AzPzPIss1CIiCvGmR/Ax7Na/tFyMzwzy7Nj4kDz\ndHIzPDPLM4dChfLuIzfDM7MccihU6O0fZFaTOMnN8MwshxwKFdwMz8zyzKFQoafPzfDMLL8cChUO\n9LsZnpnll0OhgpvhmVmeORQquBmemeWZQyGl1AzPxxTMLK8cCimlZng+pmBmeeVQSHEzPDPLO4dC\nSo/7HplZzjkUUg64Q6qZ5ZxDIcXN8Mws7xwKKW6GZ2Z551BI6e0fpKXZzfDMLL8cCim9fQO0znUz\nPDPLL4dCipvhmVneORRSevsHfDzBzHLNoZDS2z/oj6OaWa45FFLcDM/M8s6hkCgUgt5+H1Mws3yr\nKxQkvVbSCcn51ZKuk9SabWnT69DhIQqBm+GZWa7Vu6VwNzAs6XXAJuB04H+OdyVJayTtkrRb0oYq\n8xdJ+r6knZIeknTOhKqfQm6GZ2ZWfygUImIIeC/wlYj4S+DUsa4gqRm4DVgLtANXSGqvGPZJYEdE\nnAt8BPjSRIqfSm6GZ2ZWfygMSroC+Cjwo2TaePtZLgB2R8RzETEA3AVcVjGmHfg/ABHxDLBc0sl1\n1jSlSs3wfEzBzPKs3lC4CrgI+OuI+KWks4B/HOc6pwEvpi53JdPSHgPeByDpAuBMYFnlDUlaL6lT\nUmd3d3edJU9MeUvBoWBmOVZXKETEUxFxXURskbQImB8RN0/B8m8CWiXtAP4c+H/AcJXlb4qIjojo\naGtrm4LFjuZmeGZmUFfnN0k/Ad6TjH8E2CvppxHxiTGu9hLFA9Ily5JpZRFxkOJWCCo2HPol8Fy9\nxU+lnj43wzMzq3f30cLkBfx9wB0RcSHw9nGu8zBwtqSzJM0GLge2pgdIak3mAXwMuD9ZzrQ70O9m\neGZm9b4tniXpVOCDwKfquUJEDEm6FtgONAObI+JJSdck8zcCbwS+KSmAJ4GrJ3oHpoqb4ZmZ1R8K\nN1J8cf9pRDws6TXAs+NdKSK2Adsqpm1Mnf858Pr6y82Om+GZmdUZChHxHeA7qcvPAX+cVVGN0Ns/\nyOtPPqnRZZiZNVS9bS6WJd883pv83S1p1EdHj2WlH9gxM8uzeg80f4PiQeJXJ38/TKYdF9wMz8ys\nqN5QaIuIb0TEUPJ3O5DNFwYa4ODhQQrhFhdmZvWGwn5J6yQ1J3/rgP1ZFjadevsHAVjkDqlmlnP1\nhsKfUvw46m+APcD7gT/JqKZp52Z4ZmZF9ba5eCEi3hMRbRHxqoj4I46jTx/19rkZnpkZTO6X18Zq\ncXFM6fVvKZiZAZMLheOmH0QpFPyra2aWd5MJhZiyKhrMzfDMzIrGfBWUdIjqL/4CTsykogY40D/A\nIjfDMzMbOxQiYv50FdJIPX0D/nEdMzMmt/vouOFmeGZmRQ4FkrbZ/uSRmZlDAeBA/6Cb4ZmZ4VBw\nMzwzs5Tch4Kb4ZmZHZH7UCg1w1vsA81mZg6FUjM8H1MwM3MouBmemVlK7kOhx83wzMzKch8KB9wM\nz8ysLNNQkLRG0i5JuyVtqDJ/oaQfSnpM0pOSrsqynmrcDM/M7IjMQkFSM3AbsBZoB66Q1F4x7OPA\nUxFxHrAa+BtJ07ofp7fPzfDMzEqy3FK4ANgdEc9FxABwF3BZxZgA5qv4inwS0AMMZVjTKL39bnFh\nZlaSZSicBryYutyVTEv7KvBG4NfA48BfREQhw5pG6e0f8PEEM7NEow80/2dgB/BqYCXwVUkLKgdJ\nWi+pU1Jnd3f3lBbgZnhmZkdkGQovAaenLi9LpqVdBXwvinYDvwTeUHlDEbEpIjoioqOtrW1KizzQ\nP+jfUjAzS2QZCg8DZ0s6Kzl4fDmwtWLMr4C3AUg6Gfg94LkMaxqh1AzPoWBmVpTZ5zAjYkjStcB2\noBnYHBFPSrommb8R+Dxwu6THKf7E519FxL6saqrkZnhmZiNl+uH8iNgGbKuYtjF1/tfAO7KsYSyl\nvkduhmdmVtToA80NVeqQ6t1HZmZF+Q6FZEvBoWBmVpTrUHAzPDOzkXIdCqVmeD7QbGZWlOtQKDXD\nmze7udGlmJnNCLkOBTfDMzMbKdeh0ONmeGZmI+Q6FA64GZ6Z2Qi5DgU3wzMzGynXodDrZnhmZiPk\nNhQKheCAjymYmY2Q21AoNcNr9ZaCmVlZbkPBzfDMzEbLbSi4GZ6Z2Wj5DQU3wzMzGyW3oeBmeGZm\no+U2FMpbCg4FM7Oy/IZC/yCzm5vcDM/MLCW/odBXbHHhZnhmZkfkNhTcDM/MbLTchsKB/gF/8sjM\nrEJuQ6Gnb4BF/uKamdkImYaCpDWSdknaLWlDlfl/KWlH8veEpGFJi7OsqcTN8MzMRsssFCQ1A7cB\na4F24ApJ7ekxEXFrRKyMiJXAfwPui4ierGoqcTM8M7PqstxSuADYHRHPRcQAcBdw2RjjrwC2ZFhP\nWakZnrcUzMxGyjIUTgNeTF3uSqaNImkusAa4O8N6ynrKX1zzMQUzs7SZcqD53cBPa+06krReUqek\nzu7u7kkvrLfffY/MzKrJMhReAk5PXV6WTKvmcsbYdRQRmyKiIyI62traJl1Yb1+xQ6qPKZiZjZRl\nKDwMnC3pLEmzKb7wb60cJGkhcAnwgwxrGaHHWwpmZlXNyuqGI2JI0rXAdqAZ2BwRT0q6Jpm/MRn6\nXuBfIqIvq1oquRmemVl1mYUCQERsA7ZVTNtYcfl24PYs66jkZnhmZtXNlAPN08rN8MzMqstlKLgZ\nnplZdbkMhd4+N8MzM6smn6HgLQUzs6pyGgqDtM71t5nNzCrlLhTcDM/MrLbchYKb4ZmZ1Za7UHAz\nPDOz2nIXCm6GZ2ZWW+5CocfN8MzMaspdKHhLwcystvyFgpvhmZnVlLtQ6OkfcDM8M7MachcKB/oG\nWTTPzfDMzKrJXSj09LvvkZlZLbkLBTfDMzOrLX+h4BYXZmY15TAUBv1tZjOzGnIVCsNJMzzvPjIz\nqy5XoXDwFTfDMzMbS65CofRtZh9TMDOrLpeh4B/YMTOrLtNQkLRG0i5JuyVtqDFmtaQdkp6UdF+W\n9bgZnpnZ2GZldcOSmoHbgP8EdAEPS9oaEU+lxrQCfwesiYhfSXpVVvWAm+GZzSSDg4N0dXVx+PDh\nRpdyXJkzZw7Lli2jpeXo9ohkFgrABcDuiHgOQNJdwGXAU6kxVwLfi4hfAUTE3gzrcTM8sxmkq6uL\n+fPns3z5credmSIRwf79++nq6uKss846qtvIcvfRacCLqctdybS01wOLJP1E0iOSPpJhPW6GZzaD\nHD58mCVLljgQppAklixZMqmtryy3FOpd/vnA24ATgZ9LeiAifpEeJGk9sB7gjDPOOOqF9fYNuBme\n2Qzi/4tTb7LrNMsthZeA01OXlyXT0rqA7RHRFxH7gPuB8ypvKCI2RURHRHS0tbUddUG9/YM+nmBm\nAOzfv5+VK1eycuVKTjnlFE477bTy5YGBgbpu46qrrmLXrl11L/NrX/sa119//dGWPC2y3FJ4GDhb\n0lkUw+ByiscQ0n4AfFXSLGA2cCHwxawKcjM8MytZsmQJO3bsAOBzn/scJ510EjfccMOIMRFBRNDU\nVP398ze+8Y3M65xumW0pRMQQcC2wHXga+F8R8aSkayRdk4x5GvhnYCfwEPC1iHgiq5p63AzPzMax\ne/du2tvb+dCHPsSKFSvYs2cP69evp6OjgxUrVnDjjTeWx1588cXs2LGDoaEhWltb2bBhA+eddx4X\nXXQRe/fW/7mZb33rW7zpTW/inHPO4ZOf/CQAQ0NDfPjDHy5P//KXvwzAF7/4Rdrb2zn33HNZt27d\n1N55Mj6mEBHbgG0V0zZWXL4VuDXLOkoOuBme2Yz033/4JE/9+uCU3mb7qxfw2XevOKrrPvPMM9xx\nxx10dHQAcNNNN7F48WKGhoZ461vfyvvf/37a29tHXOfll1/mkksu4aabbuITn/gEmzdvZsOGql/P\nGqGrq4tPf/rTdHZ2snDhQt7+9rfzox/9iLa2Nvbt28fjjz8OwIEDBwC45ZZbeOGFF5g9e3Z52lTK\nzTea3QzPzOr12te+thwIAFu2bGHVqlWsWrWKp59+mqeeemrUdU488UTWrl0LwPnnn8/zzz9f17Ie\nfPBBLr30UpYuXUpLSwtXXnkl999/P6973evYtWsX1113Hdu3b2fhwoUArFixgnXr1nHnnXce9XcR\nxtLoTx9NGzfDM5u5jvYdfVbmzZtXPv/ss8/ypS99iYceeojW1lbWrVtX9SOfs2cfeW1pbm5maGho\nUjUsWbKEnTt3cs8993Dbbbdx9913s2nTJrZv3859993H1q1b+cIXvsDOnTtpbp66j9nnZkvBzfDM\n7GgcPHiQ+fPns2DBAvbs2cP27dun9PYvvPBC7r33Xvbv38/Q0BB33XUXl1xyCd3d3UQEH/jAB7jx\nxht59NFHGR4epquri0svvZRbbrmFffv20d/fP6X15GZLodziwqFgZhOwatUq2tvbecMb3sCZZ57J\nW97ylknd3te//nW++93vli93dnby+c9/ntWrVxMRvPvd7+Zd73oXjz76KFdffTURgSRuvvlmhoaG\nuPLKKzl06BCFQoEbbriB+fPnT/YujqCImNIbzFpHR0d0dnZO+Ho/fuq3/NkdnWy99i2cu6w1g8rM\nbCKefvpp3vjGNza6jONStXUr6ZGI6KhxlbLc7D5aPK+FteecwskL5jS6FDOzGSs3u4/OP3Mx55+5\nuNFlmJnNaLnZUjAzs/E5FMysYY61Y5rHgsmuU4eCmTXEnDlz2L9/v4NhCpV+T2HOnKM/dpqbYwpm\nNrMsW7aMrq4uuru7G13KcaX0y2tHy6FgZg3R0tJy1L8OZtnx7iMzMytzKJiZWZlDwczMyo65NheS\nuoEXjvLqS4F9U1jOVJmpdcHMrc11TYzrmpjjsa4zI2Lc3zM+5kJhMiR11tP7Y7rN1Lpg5tbmuibG\ndU1Mnuvy7iMzMytzKJiZWVneQmFTowuoYabWBTO3Ntc1Ma5rYnJbV66OKZiZ2djytqVgZmZjOC5D\nQdIaSbsk7Za0ocp8SfpyMn+npFXTUNPpku6V9JSkJyX9RZUxqyW9LGlH8veZrOtKlvu8pMeTZY76\nWbsGra/fS62HHZIOSrq+Ysy0rS9JmyXtlfREatpiST+W9GxyuqjGdcd8PmZQ162Snkkeq+9LqvpT\ng+M97hnU9TlJL6Uer3fWuO50r69vp2p6XtKOGtfNZH3Vem1o2PMrIo6rP6AZ+DfgNcBs4DGgvWLM\nO4F7AAFvBh6chrpOBVYl5+cDv6hS12rgRw1YZ88DS8eYP+3rq8pj+huKn7NuyPoC/gBYBTyRmnYL\nsCE5vwG4+WiejxnU9Q5gVnL+5mp11fO4Z1DX54Ab6nisp3V9Vcz/G+Az07m+ar02NOr5dTxuKVwA\n7I6I5yJiALgLuKxizGXAHVH0ANAq6dQsi4qIPRHxaHL+EPA0cFqWy5xC076+KrwN+LeIONovLU5a\nRNwP9FRMvgz4ZnL+m8AfVblqPc/HKa0rIv4lIoaSiw8AR98ycwrrqtO0r68SSQI+CGyZquXVWVOt\n14aGPL+Ox1A4DXgxdbmL0S++9YzJjKTlwH8AHqwy+/eTzf57JK2YppIC+FdJj0haX2V+Q9cXcDm1\n/6M2Yn2VnBwRe5LzvwFOrjKm0evuTylu5VUz3uOehT9PHq/NNXaHNHJ9/UfgtxHxbI35ma+viteG\nhjy/jsdQmNEknQTcDVwfEQcrZj8KnBER5wJfAf5pmsq6OCJWAmuBj0v6g2la7rgkzQbeA3ynyuxG\nra9RorgtP6M+yifpU8AQcGeNIdP9uP89xd0cK4E9FHfVzCRXMPZWQqbra6zXhul8fh2PofAScHrq\n8rJk2kTHTDlJLRQf9Dsj4nuV8yPiYET8e3J+G9AiaWnWdUXES8npXuD7FDdJ0xqyvhJrgUcj4reV\nMxq1vlJ+W9qNlpzurTKmUc+1PwH+EPhQ8oIySh2P+5SKiN9GxHBEFIB/qLG8Rq2vWcD7gG/XGpPl\n+qrx2tCQ59fxGAoPA2dLOit5l3k5sLVizFbgI8mnat4MvJzaTMtEsr/y68DTEfG3NcackoxD0gUU\nH5/9Gdc1T9L80nmKBymfqBg27esrpea7t0asrwpbgY8m5z8K/KDKmHqej1NK0hrgvwLviYj+GmPq\nedynuq70caj31ljetK+vxNuBZyKiq9rMLNfXGK8NjXl+TfWR9JnwR/HTMr+geFT+U8m0a4BrkvMC\nbkvmPw50TENNF1Pc/NsJ7Ej+3llR17XAkxQ/QfAA8PvTUNdrkuU9lix7RqyvZLnzKL7IL0xNa8j6\nohhMe4BBivttrwaWAP8beBb4V2BxMvbVwLaxno8Z17Wb4n7m0vNsY2VdtR73jOv6x+T5s5PiC9ep\nM2F9JdNvLz2vUmOnZX2N8drQkOeXv9FsZmZlx+PuIzMzO0oOBTMzK3MomJlZmUPBzMzKHApmZlbm\nUDCrQdKnkq6VO5POmBdKul7S3EbXZpYVfyTVrApJFwF/C6yOiN8l35SeDfyM4vc09jW0QLOMeEvB\nrLpTgX0R8TuAJATeT/GLQ/dKuhdA0jsk/VzSo5K+k/SvKfXevyXpv/+QpNcl0z8g6QlJj0m6vzF3\nzaw2bymYVZG8uP9fYC7Fb5N+OyLuk/Q8yZZCsvXwPWBtRPRJ+ivghIi4MRn3DxHx15I+AnwwIv5Q\n0uPAmoh4SVJrRBxoyB00q8FbCmZVRLHR3vnAeqAb+HbSZC7tzRR/DOWnKv5a10eBM1Pzt6ROL0rO\n/xS4XdKfUfyBFLMZZVajCzCbqSJiGPgJ8JPkHf5HK4YI+HFEXFHrJirPR8Q1ki4E3gU8Iun8iJjO\nJn5mY/KWglkVKv5G9NmpSSuBF4BDFH8yEYpN+N6SOl4wT9LrU9f5L6nTnydjXhsRD0bEZyhugaTb\nHps1nLcUzKo7CfiKij96P0Sx8+h6iq28/1nSryPirckupS2STkiu92mKHSsBFknaCfwuuR7ArUnY\niGIHzMem5d6Y1ckHms0ykD4g3ehazCbCu4/MzKzMWwpmZlbmLQUzMytzKJiZWZlDwczMyhwKZmZW\n5lAwM7Myh4KZmZX9fw6+5n1/ljJtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0f02ab668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "a = [i[0] for i in records]\n",
    "plt.plot(a, label = 'Train Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kale/miniconda3/envs/kale/lib/python3.6/site-packages/torch/autograd/__init__.py:92: UserWarning: retain_variables option is deprecated and will be removed in 0.3. Use retain_graph instead.\n",
      "  warnings.warn(\"retain_variables option is deprecated and will be removed in 0.3. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0轮，训练损失：3.91，训练进度：0.0%，（0m 0s）\n",
      "第0轮，训练损失：2.36，训练进度：4.98%，（0m 39s）\n",
      "第0轮，训练损失：2.00，训练进度：9.96%，（1m 17s）\n",
      "第0轮，训练损失：1.82，训练进度：14.94%，（1m 58s）\n",
      "第0轮，训练损失：1.71，训练进度：19.93%，（2m 37s）\n",
      "第0轮，训练损失：1.64，训练进度：24.91%，（3m 23s）\n",
      "第0轮，训练损失：1.59，训练进度：29.89%，（5m 10s）\n",
      "第1轮，训练损失：1.63，训练进度：33.33%，（7m 33s）\n",
      "第1轮，训练损失：1.28，训练进度：38.31%，（8m 14s）\n",
      "第1轮，训练损失：1.28，训练进度：43.3%，（8m 53s）\n",
      "第1轮，训练损失：1.27，训练进度：48.28%，（9m 35s）\n",
      "第1轮，训练损失：1.27，训练进度：53.26%，（10m 35s）\n",
      "第1轮，训练损失：1.26，训练进度：58.24%，（11m 46s）\n",
      "第1轮，训练损失：1.26，训练进度：63.22%，（13m 35s）\n",
      "第2轮，训练损失：1.24，训练进度：66.67%，（16m 25s）\n",
      "第2轮，训练损失：1.23，训练进度：71.65%，（17m 5s）\n",
      "第2轮，训练损失：1.23，训练进度：76.63%，（17m 46s）\n",
      "第2轮，训练损失：1.23，训练进度：81.61%，（18m 32s）\n",
      "第2轮，训练损失：1.23，训练进度：86.59%，（19m 30s）\n",
      "第2轮，训练损失：1.23，训练进度：91.57%，（20m 12s）\n",
      "第2轮，训练损失：1.23，训练进度：96.56%，（21m 14s）\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "records = []\n",
    "# 开始训练循环\n",
    "for epoch in range(num_epoch):\n",
    "    train_loss=0\n",
    "    # 按所有数据的行数随机循环\n",
    "    for i in range(all_line_num):\n",
    "        loss = train_LSTM()\n",
    "        train_loss+=loss\n",
    "        \n",
    "        #每隔3000步，跑一次校验集，并打印结果\n",
    "        if i % 3000 == 0:#还可以采用if i>0\n",
    "            training_process = (all_line_num * epoch + i) / (all_line_num * num_epoch) * 100\n",
    "            training_process = '%.2f' % training_process\n",
    "            print('第{}轮，训练损失：{:.2f}，训练进度：{}%，（{}）'\\\n",
    "                .format(epoch, train_loss.data.numpy()[0]/(i+1), float(training_process), time_since(start)))\n",
    "            records.append([train_loss.data.numpy()[0]/(i+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe0f3886160>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xt8VPWd//HXZyZ3CISEKJckoKAiKAJGvLX1srZeW21r\nXbVotf0tq3XXuq3tum3XtbrdVbfttl5a13qptv7UtrZqvWvFeqmokQVELnIRJIASAiRACMlkPvvH\nnIxDSGBIcjIh834+HvOYM2e+Z+aTM8O8Oed8z/eYuyMiIgIQyXQBIiLSfygUREQkSaEgIiJJCgUR\nEUlSKIiISJJCQUREkhQKIiKSpFAQEZEkhYKIiCTlhP0GZhYFaoA17n5Wh+cM+BlwBtAEXOLuc3b3\nesOHD/exY8eGVK2IyMD09ttvb3D38j21Cz0UgG8Ai4AhnTx3OnBQcDsa+EVw36WxY8dSU1PT2zWK\niAxoZrYqnXah7j4yswrgTOCuLpqcDdzvCbOBEjMbGWZNIiLStbCPKfwU+A4Q7+L50cDqlMe1wbyd\nmNlMM6sxs5q6urrer1JERIAQQ8HMzgLWu/vbPX0td7/T3avdvbq8fI+7xEREpJvCPKZwPPA5MzsD\nKACGmNlv3H1GSps1QGXK44pgnogMcK2trdTW1tLc3JzpUgaUgoICKioqyM3N7dbyoYWCu/8L8C8A\nZnYicHWHQAB4HPgHM3uIxAHmBndfF1ZNItJ/1NbWUlxczNixY0l0RJSecnfq6+upra3lgAMO6NZr\n9Pl5CmZ2mZldFjx8ClgBLAN+CXy9r+sRkcxobm6mrKxMgdCLzIyysrIebX31RZdU3P0l4KVg+o6U\n+Q5c0Rc1iEj/o0DofT1dp1lzRvPiDxu56ZnFNGxvzXQpIiL9VtaEwgf1TfzipeWs3LAt06WISD9Q\nX1/PlClTmDJlCiNGjGD06NHJxy0tLWm9xqWXXsqSJUvSfs+77rqLq666qrsl94k+2X3UH1SVFQHw\nwcYmjqgsyXA1IpJpZWVlzJ07F4DrrruOwYMHc/XVV+/Uxt1xdyKRzv//fO+994ZeZ1/Lmi2FqtKP\nQ0FEpCvLli1j4sSJfPnLX2bSpEmsW7eOmTNnUl1dzaRJk7j++uuTbT/xiU8wd+5cYrEYJSUlXHPN\nNRxxxBEce+yxrF+/Pu33/M1vfsPhhx/OYYcdxne/+10AYrEYF110UXL+LbfcAsB///d/M3HiRCZP\nnsyMGR07dPZc1mwpFOXlMHxwPh/UKxRE+psf/OldFq5t7NXXnDhqCP/22UndWnbx4sXcf//9VFdX\nA3DjjTdSWlpKLBbjpJNO4txzz2XixIk7LdPQ0MAJJ5zAjTfeyDe/+U3uuecerrnmmj2+V21tLd//\n/vepqalh6NChnHLKKTzxxBOUl5ezYcMG3nnnHQA2b94MwM0338yqVavIy8tLzutNWbOlAFBVWqgt\nBRHZo3HjxiUDAeDBBx9k2rRpTJs2jUWLFrFw4cJdliksLOT0008H4Mgjj2TlypVpvdcbb7zBySef\nzPDhw8nNzeXCCy/k5ZdfZvz48SxZsoQrr7ySZ599lqFDhwIwadIkZsyYwQMPPNDtE9R2J2u2FCCx\nC+mtlZsyXYaIdNDd/9GHZdCgQcnppUuX8rOf/Yw333yTkpISZsyY0el5AHl5ecnpaDRKLBbrUQ1l\nZWXMnz+fp59+mttvv51HHnmEO++8k2effZa//OUvPP744/zHf/wH8+fPJxqN9ui9UmXXlkLZINY1\nbKcl1tX4fCIiO2tsbKS4uJghQ4awbt06nn322V59/aOPPppZs2ZRX19PLBbjoYce4oQTTqCurg53\n50tf+hLXX389c+bMoa2tjdraWk4++WRuvvlmNmzYQFNT7+79yLothbjDms3bOWD4oD0vICJZb9q0\naUycOJEJEyYwZswYjj/++B693t13383vf//75OOamhpuuOEGTjzxRNydz372s5x55pnMmTOHr33t\na7g7ZsZNN91ELBbjwgsvZMuWLcTjca6++mqKi4t7+ifuxBInFe87qqurvbsX2Xnz/Y2c9z+vc99X\np3PCwRptVSSTFi1axKGHHprpMgakztatmb3t7tVdLJKUXbuP1C1VRGS3sioU9ivOJy8nwmqFgohI\np7IqFCIRo6q0SOcqiPQT+9ru631BT9dpVoUCJHYhrdKWgkjGFRQUUF9fr2DoRe3XUygoKOj2a2RV\n7yNIhMKb729MHtEXkcyoqKigtrYWXXe9d7Vfea27si4UKkuL2LojxqamVkoH5e15AREJRW5ubrev\nDibhybrdR2PUA0lEpEtZFwqpQ2iLiMjOsi4UKocFoVCvi+2IiHSUdaFQmBelvDhfWwoiIp3IulCA\nRA8khYKIyK6yMhTGlBaxeuP2TJchItLvZGUoVJYWsVZDaIuI7CIrQ6GqtAh3qN2kXUgiIqmyMxTU\nLVVEpFPZGQrBCWwaLVVEZGdZGQr7FeeTnxPRloKISAdZGQpmiSG0V2kIbRGRnYQWCmZWYGZvmtk8\nM3vXzH7QSZsTzazBzOYGt2vDqqcjnasgIrKrMEdJ3QGc7O5bzSwXeNXMnnb32R3aveLuZ4VYR6cq\nS4uYvaJeQ2iLiKQIbUvBE7YGD3ODW7+5msaYsiK2tbSxcVtLpksREek3Qj2mYGZRM5sLrAeed/c3\nOml2nJnNN7OnzWxSF68z08xqzKymty7IUaUhtEVEdhFqKLh7m7tPASqA6WZ2WIcmc4Aqd58M3Ao8\n2sXr3Onu1e5eXV5e3iu1KRRERHbVJ72P3H0zMAs4rcP8xvZdTO7+FJBrZsP7oqaK5BDaCgURkXZh\n9j4qN7OSYLoQ+DSwuEObERYc5TWz6UE99WHVlKowL8p+GkJbRGQnYfY+GgncZ2ZREj/2v3X3J8zs\nMgB3vwM4F7jczGLAduB8d++zg9FjytQtVUQkVWih4O7zgamdzL8jZfo24LawatiTytIiZi/vkw0T\nEZF9Qlae0dyuqrSIdY3N7Ii1ZboUEZF+IetDITGEti64IyICCgVA3VJFRNpldyiUaQhtEZFUWR0K\n5YPzKciN6FwFEZFAVodCcghtbSmIiABZHgqQOK6g3UciIgkKhdJBfLCxiT48Z05EpN9SKJQW0tTS\nRr2G0BYRUSi090BSt1QREYXCx+cqqAeSiIhCITmEtrYUREQUCgW5UUYMKVAoiIigUAASu5AUCiIi\nCgUgMYS2zlUQEVEoAIkthQ8bm2lu1RDaIpLdFApAVVmhhtAWEUGhACTOagaNlioiolBA11UQEWmn\nUACGD86jMDfKKp3AJiJZTqHAx0Noa0tBRLKdQiFQVaZuqSIiCoVA+5aChtAWkWymUAhUlRaxvbWN\nDVs1hLaIZC+FQuDjHkjbMlyJiEjmKBQCleqWKiKiUGhXMawQM/igXmc1i0j2Ci0UzKzAzN40s3lm\n9q6Z/aCTNmZmt5jZMjObb2bTwqpnTzSEtogI5IT42juAk919q5nlAq+a2dPuPjulzenAQcHtaOAX\nwX1GaLRUEcl2oW0peMLW4GFucOvY3/Ns4P6g7WygxMxGhlXTnlSVFrFKB5pFJIuFekzBzKJmNhdY\nDzzv7m90aDIaWJ3yuDaYlxFjSov4qHGHhtAWkawVaii4e5u7TwEqgOlmdlh3XsfMZppZjZnV1NXV\n9W6RKarKEj2QajdpF5KIZKc+6X3k7puBWcBpHZ5aA1SmPK4I5nVc/k53r3b36vLy8tDqVLdUEcl2\nYfY+KjezkmC6EPg0sLhDs8eBi4NeSMcADe6+Lqya9iR5AptGSxWRLBVm76ORwH1mFiURPr919yfM\n7DIAd78DeAo4A1gGNAGXhljPHpUNyqMoL8oqbSmISJYKLRTcfT4wtZP5d6RMO3BFWDXsrfYhtNUt\nVUSylc5o7kDXVRCRbKZQ6EBDaItINlModFBVVkRza5y6rTsyXYqISJ9TKHRQqR5IIpLFFAodjNG5\nCiKSxRQKHYxuH0JboSAiWUih0EF+TpSRGkJbRLKUQqETGkJbRLKVQqETY8qKWKUDzSKShRQKnagq\nLWL9lh1sb9EQ2iKSXRQKnWjvlqohtEUk2ygUOlGlbqkikqUUCp1oDwUdVxCRbKNQ6ETpoDwG5+do\nS0FEso5CoRNmpm6pIpKVFApdqCot1JaCiGQdhUIXNIS2iGQjhUIXqkqL2BGLs36LhtAWkeyRViiY\n2Tgzyw+mTzSzK82sJNzSMquqbBCgbqkikl3S3VJ4BGgzs/HAnUAl8P9Dq6ofqNJ1FUQkC6UbCnF3\njwGfB251928DI8MrK/NGl2gIbRHJPumGQquZXQB8BXgimJcbTkn9Q15OhFFDC9UtVUSySrqhcClw\nLPBDd3/fzA4Afh1eWf1DVWkRqxQKIpJFctJp5O4LgSsBzGwYUOzuN4VZWH9QVVrEi0vWZ7oMEZE+\nk27vo5fMbIiZlQJzgF+a2U/CLS3zqsqKqNMQ2iKSRdLdfTTU3RuBLwD3u/vRwCnhldU/tA+hvVpD\naItIlkg3FHLMbCRwHh8faB7w1C1VRLJNuqFwPfAssNzd3zKzA4Gl4ZXVP4xpH0JbB5tFJEukFQru\n/jt3n+zulwePV7j7F3e3jJlVmtksM1toZu+a2Tc6aXOimTWY2dzgdm33/oxwlBTlUpyfo26pIpI1\n0up9ZGYVwK3A8cGsV4BvuHvtbhaLAd9y9zlmVgy8bWbPBz2ZUr3i7mftbeF9oX0IbZ3AJiLZIt3d\nR/cCjwOjgtufgnldcvd17j4nmN4CLAJGd7/UzKhSKIhIFkk3FMrd/V53jwW3XwHl6b6JmY0FpgJv\ndPL0cWY238yeNrNJ6b5mXxlTlrjYTjyuIbRFZOBLNxTqzWyGmUWD2wygPp0FzWwwiQH1rgq6taaa\nA1S5+2QSu6ce7eI1ZppZjZnV1NXVpVly76jUENoikkXSDYWvkuiO+iGwDjgXuGRPC5lZLolAeMDd\n/9DxeXdvdPetwfRTQK6ZDe+k3Z3uXu3u1eXlaW+g9Ipkt1TtQhKRLJBu76NV7v45dy939/3c/Rxg\nT72PDLgbWOTunZ79bGYjgnaY2fSgnrS2QPqKQkFEsklavY+68E3gp7t5/njgIuAdM5sbzPsuUAXg\n7neQ2OK43MxiwHbgfO9n178cVVJIRENoi0iW6Eko2O6edPdX02hzG3BbD2oIXV5OhFElGkJbRLJD\nT67R3K/+Rx+mqtIiVtVvy3QZIiKh2+2WgpltofMffwMKQ6moH6oqLeKFRRpCW0QGvt2GgrsX91Uh\n/VllaREbtu6gqSVGUV5P9riJiPRvPdl9lDXaeyCt3rg9w5WIiIRLoZCGMWWJUFip4woiMsApFNIw\nrnwwxQU5PPTmB5kuRUQkVAqFNAzKz+HKkw9i1pI6Xn6vb4fZEBHpSwqFNF183BjGlBXx708uJNYW\nz3Q5IiKhUCikKT8nyr+cPoH3PtrKwzWrM12OiEgoFAp74dRJI5h+QCk/ee49tjS3ZrocEZFep1DY\nC2bGv545kY1NLdw+a3mmyxER6XUKhb10eMVQvjC1gntefV/jIYnIgKNQ6IZvn3oI0Yhx4zOLM12K\niEivUih0w4ihBfz9CQfy5Px11KzcmOlyRER6jUKhm2Z+6kD2H5LPDU8u0vWbRWTAUCh0U1FeDt85\ndQLzVm/m8XlrM12OiEivUCj0wOenjubw0UO56ZnFbG9py3Q5IiI9plDogUjE+NezJrKuoZm7XlmR\n6XJERHpModBD0w8o5fTDRvCLvyxnfWNzpssREekRhUIvuOb0CcTanB89tyTTpYiI9IhCoReMKRvE\nJceP5Xdv17JgTUOmyxER6TaFQi+54qTxDCvK44dPLsJdXVRFZN+kUOglQwtz+adTDuL1FfU8v/Cj\nTJcjItItCoVedMH0KsbvN5j/fHoxLTFdc0FE9j0KhV6UE43wvTMP5f0N2/j17FWZLkdEZK8pFHrZ\nSYfsx6cOLueWPy9lc1NLpssREdkrCoUQfO+MQ9nS3MpPX1ia6VJERPaKQiEEh4wo5oLpVfxm9iqW\n123NdDkiImkLLRTMrNLMZpnZQjN718y+0UkbM7NbzGyZmc03s2lh1dPX/unTB1OYG+U/n1qU6VJE\nRNIW5pZCDPiWu08EjgGuMLOJHdqcDhwU3GYCvwixnj41fHA+V5w8nhcWree1ZRsyXY6ISFpCCwV3\nX+fuc4LpLcAiYHSHZmcD93vCbKDEzEaGVVNfu+S4sVSWFnLDEwtp0zUXRGQf0CfHFMxsLDAVeKPD\nU6OB1SmPa9k1OPZZBblRrjntUBZ/uIV7X3s/0+WIiOxR6KFgZoOBR4Cr3L2xm68x08xqzKymrq6u\ndwsM2RmHj+DkCfvx708u4ifPv6chMESkXws1FMwsl0QgPODuf+ikyRqgMuVxRTBvJ+5+p7tXu3t1\neXl5OMWGxMy4Y8aRnFddwS1/XspVD8+luVUX5BGR/inM3kcG3A0scvefdNHsceDioBfSMUCDu68L\nq6ZMycuJcNMXJ/PtUw/hsblrmXHXG2zcphPbRKT/CXNL4XjgIuBkM5sb3M4ws8vM7LKgzVPACmAZ\n8Evg6yHWk1FmxhUnjee2C6cyf00Dn//5azqHQUT6HdvX9nFXV1d7TU1NpsvokTkfbOLv7qshFnfu\nmHEkx44ry3RJIjLAmdnb7l69p3Y6ozkDplUN49Erjqe8OJ+L73mDR96uzXRJIiKAQiFjKkuLeOTy\n45h+QCnf+t08fvzcEvVMEpGMUyhk0NDCXH516XT+trqSW19cxpUPqWeSiGRWTqYLyHa50Qg3fvFw\nxg4fxE3PLGbt5u3cedGRlA3Oz3RpIpKFtKXQD5gZl584jp9/eRoL1jTw+Z//lWXr1TNJRPqeQqEf\nOePwkTw08xiaWmJ84eev8dflGkhPRPqWQqGfmVo1jD9+/Xj2H1LAxXe/ye9qVu95IRGRXqJQ6Icq\nS4v4/eXHcfSBpXz79/P5wZ/epaGpNdNliUgWUCj0U+09ky46Zgz3vraST978Ire9uJRtO2KZLk1E\nBjCFQj+WG41wwzmH8fQ3Psn0A8r40XPv8ambZ3HXKyvUdVVEQqFhLvYh//vBJn783Hu8umwDI4YU\n8I9/M57zqivJjSrbRWT30h3mQqGwD3p9eT0/em4Jb6/aRFVpEVedchBnTxlNNGKZLk1E+imNfTSA\nHTuujN9fdiz3XnIUg/Nz+OZv53HaT1/m6XfWaagMEekRhcI+ysw4acJ+PPGPn+D2C6cRd+fyB+bw\n2dteZdaS9QoHEekWhcI+LhIxzpw8kuf+6QR+9KUj2NzUyqX3vsV5//M6s1fUZ7o8EdnH6JjCANMS\ni/NwzWpue3EpHzXu4LhxZZxXXcmnJ+7PoHwNdSWSrXSgOcs1t7bx69dXce9r77O2oZnC3CifmbQ/\nZ08ZxScPKlePJZEso1AQAOJx562VG3l07lqeemcdDdtbKR2Ux5mHj+ScqaOYVjWMxOW0RWQgUyjI\nLlpicf7yXh2Pzl3DCws/YkcsTmVpIWcfMZqzp4zioP2LM12iiIREoSC7taW5lWff/YjH5q7htWUb\niDtMHDmEc6aO4nNHjGbE0IJMlygivUihIGlbv6WZJ+at47G5a5hX24AZHH1AKWdPGc1Jh+yngBAZ\nABQK0i0r6rby2Ny1PDZ3DSvrmwA4sHwQx40r4/hxwzl2XBklRXmhvHdzaxuL1jWyYE0Dh1eUMKWy\nJJT3EclGCgXpEXdn0botvLZsA68t38Cb72+kqaUNM5g0agjHjxvOceOHc9TYYRTl7X1X19a2OO99\ntIV3ahuYV9vA/NrNLPlwC7F44vs4fHA+L159AkMKcnv7TxPJSgoF6VUtsTjzazfz2rJ6Xlu+gf/9\nYBOtbU5u1JhaNSyxJTF+OFMqS3bp7hqPOys2bGV+bUNw28y7axvZEYsDMKQgh8kVJRxeMZQjKoaS\nnxPlq/e9xSXHjeXfPjspE3+uyICjUJBQNbXEeGvlJv66fAN/XVbPgrUNuENRXpTpB5Ry9AFlbGpq\nYX7tZhasaWRrcB2Iorwoh40ayuEVQ5lcMZTJFSWMLSvapVvsd//4Dg+/tZonr/wEE0YMycSfKDKg\nKBSkT21uamH2ivrklsSKum3kRSMcOmoIk0d/HADj9xuc1mium7a1cNKPX+Lg/Yp5+O+P0bkUIj2U\nbiho3APpFSVFeZx22EhOO2wkABu3tTA4P4e8nO6dOT1sUB7fOXUC3/3jOzw2dy3nTB3dm+WKSBc0\n1oGEonRQXrcDod3fHlXJ5Iqh/PCpRWxp1jWqRfpCaKFgZveY2XozW9DF8yeaWYOZzQ1u14ZVi+yb\nohHj+rMPY8PWHfzshaWZLkckK4S5pfAr4LQ9tHnF3acEt+tDrEX2UVMqSzj/qEru/etK3vtoS6bL\nERnwQgsFd38Z2BjW60v2+PapEyguyOHaxxbo4kEiIcv0MYXjzGy+mT1tZuqQLp0qHZTH1Z85hNkr\nNvKn+esyXY7IgJbJUJgDVLn7ZOBW4NGuGprZTDOrMbOaurq6PitQ+o8Lpldx2Ogh/PDJhclzHkSk\n92UsFNy90d23BtNPAblmNryLtne6e7W7V5eXl/dpndI/tB90/qhxB7f8WQedRcKSsVAwsxEWnJFk\nZtODWnRRYenStKphnFddwT2vvs9SHXQWCUWYXVIfBF4HDjGzWjP7mpldZmaXBU3OBRaY2TzgFuB8\n11FE2YN/Pm0CRXlR/u3xd3XQWSQEoZ3R7O4X7OH524Dbwnp/GZjKBudz9amHcO1j7/LkO+s4a/Ko\nTJckMqBkuveRyF778tFjmDhyCP/+xCK26aCzSK9SKMg+JxoxbjhnEh82NnPri8syXY7IgKJQkH3S\nkWNK+eK0Cu5+dQXL67ZmuhyRAUOhIPusa06fQEFulOt00Fmk1ygUZJ9VXpzPtz59MK8s3cAzCz7M\ndDkiA4JCQfZpM44Zw4QRxdzwxEKaWnTQWaSnFAqyT8uJRrjhnMNY29DM7bN00FmkpxQKss87amwp\nX5g6ml++/D4rdNBZpEcUCjIgXHPGBPJzIlz3p4U66CzSAwoFGRD2Ky7gqk8fzMvv1fHMgg8VDCLd\nFNowFyJ97SvHjuG3b63m8gfmYAaFuVGK8qIUBPeFuVEKd7rPoTAvQlFeTrJNQU6EnGiEnIgRjRg5\nUSMaSXmcvI+kPP/x/Nxg2dxoJDEdNXIjwX00Qm7UCMaBFOmXFAoyYOREI9xz6VE8NncN21va2N7S\nRlNrG80tbTS1tLG9NTFvw9YWmlpiNLfG2d7alpzuK+0hkheERk40Qm7EyM+Nkp8TSd4X7HIfIT8n\n2ul9bjSSDKWO4ZUT3TXMcqMfP87LiTCkMIfC3KgCSxQKMrCMLink6yeO3+vl4nGnOdZGc2ucWDxO\nW9yJtXniPt5+H08+ju8032mLx2ltSywTC6Zb2+LE2lKm44n7xHxPmR+nJea0tMXZ0dpGcyxx37C9\nlR2tbeyI7Tx/RyzxWr0tN2oMKchlSGEuQwpygvvgcWHOTs8NLcxNPj+sKJeSojyiEQXKQKBQEAEi\nEaMoL4eivExXkp5YW5wdsTjNQUi0BEGRGl6tbR3CrO3jAGtv29rm7Ii1saU5RuP2Vhq2t9IYTDc2\nt7J283Yaticet7R1vTVlRjIghg3KY1hR+y31ccr0oFxKChNB0hZ34p64tcWdeBzagsfxuNMWzHeH\ntuBxPO6YQTQSIWpGJAI5kUjyPmpGNGo7P2d0a0uo/fiUO7RHsQV/80DcslIoiOyDcqKJYx+D8vvu\nn3BzaxuNza00bo/R2BwEyPZWNm1rYVNTK5uaEvebm1r4qLGZJR9uYeO2Fra3tvVZjXsSjSSCwiz4\ngXdwfKcffHfHSYRAOtrDJmJgWBAWEDHDSNzT/jhlviUfJ5Zrf53dLX/+UZX8v08eGMKa+ZhCQUTS\nUpCbOGi/X/HeLdfc2sbmplY2bmthc1MLG9vDY1sLcYdoJLGlFjUjYhZMJ37AzSz5Qx6JJH44o5FE\nO4fkbrz2LYrUXXvJe/dddvu5O6T+iBP8z5/E//zb55H8AU/8Le3t3SHungyQxDTEU0PGPfE4aMtO\n7dqDJ+VxV8sHy+EwfHB+b3yUu6VQEJFQFeRGGTE0yoihBZkuRdKg8xRERCRJoSAiIkkKBRERSVIo\niIhIkkJBRESSFAoiIpKkUBARkSSFgoiIJNm+Nu68mdUBq7q5+HBgQy+W01v6a13Qf2tTXXtHde2d\ngVjXGHcv31OjfS4UesLMaty9OtN1dNRf64L+W5vq2juqa+9kc13afSQiIkkKBRERScq2ULgz0wV0\nob/WBf23NtW1d1TX3snaurLqmIKIiOxetm0piIjIbgzIUDCz08xsiZktM7NrOnnezOyW4Pn5Zjat\nD2qqNLNZZrbQzN41s2900uZEM2sws7nB7dqw6wred6WZvRO8Z00nz2difR2Ssh7mmlmjmV3VoU2f\nrS8zu8fM1pvZgpR5pWb2vJktDe6HdbHsbr+PIdT1X2a2OPis/mhmJV0su9vPPYS6rjOzNSmf1xld\nLNvX6+vhlJpWmtncLpYNZX119duQse+Xt189aIDcgCiwHDgQyAPmARM7tDkDeJrExZWOAd7og7pG\nAtOC6WLgvU7qOhF4IgPrbCUwfDfP9/n66uQz/ZBEP+uMrC/gU8A0YEHKvJuBa4Lpa4CbuvN9DKGu\nzwA5wfRNndWVzuceQl3XAVen8Vn36frq8PyPgWv7cn119duQqe/XQNxSmA4sc/cV7t4CPASc3aHN\n2cD9njAbKDGzkWEW5e7r3H1OML0FWASMDvM9e1Gfr68O/gZY7u7dPWmxx9z9ZWBjh9lnA/cF0/cB\n53SyaDrfx16ty92fc/dY8HA2UNFb79eTutLU5+urnZkZcB7wYG+9X5o1dfXbkJHv10AMhdHA6pTH\ntez645tOm9CY2VhgKvBGJ08fF2z2P21mk/qoJAdeMLO3zWxmJ89ndH0B59P1P9RMrK92+7v7umD6\nQ2D/Ttpket19lcRWXmf29LmH4R+Dz+ueLnaHZHJ9fRL4yN2XdvF86Ourw29DRr5fAzEU+jUzGww8\nAlzl7o3CXEwrAAAEC0lEQVQdnp4DVLn7ZOBW4NE+KusT7j4FOB24wsw+1Ufvu0dmlgd8DvhdJ09n\nan3twhPb8v2qK5+ZfQ+IAQ900aSvP/dfkNjNMQVYR2JXTX9yAbvfSgh1fe3ut6Evv18DMRTWAJUp\njyuCeXvbpteZWS6JD/0Bd/9Dx+fdvdHdtwbTTwG5ZjY87LrcfU1wvx74I4lN0lQZWV+B04E57v5R\nxycytb5SfNS+Gy24X99Jm0x91y4BzgK+HPyg7CKNz71XuftH7t7m7nHgl128X6bWVw7wBeDhrtqE\nub66+G3IyPdrIIbCW8BBZnZA8L/M84HHO7R5HLg46FVzDNCQspkWimB/5d3AInf/SRdtRgTtMLPp\nJD6f+pDrGmRmxe3TJA5SLujQrM/XV4ou//eWifXVwePAV4LprwCPddImne9jrzKz04DvAJ9z96Yu\n2qTzufd2XanHoT7fxfv1+foKnAIsdvfazp4Mc33t5rchM9+v3j6S3h9uJHrLvEfiqPz3gnmXAZcF\n0wbcHjz/DlDdBzV9gsTm33xgbnA7o0Nd/wC8S6IHwWzguD6o68Dg/eYF790v1lfwvoNI/MgPTZmX\nkfVFIpjWAa0k9tt+DSgD/gwsBV4ASoO2o4Cndvd9DLmuZST2M7d/z+7oWFdXn3vIdf06+P7MJ/HD\nNbI/rK9g/q/av1cpbftkfe3mtyEj3y+d0SwiIkkDcfeRiIh0k0JBRESSFAoiIpKkUBARkSSFgoiI\nJCkURLpgZt8LRq2cH4yMebSZXWVmRZmuTSQs6pIq0gkzOxb4CXCiu+8IzpTOA/5K4jyNDRktUCQk\n2lIQ6dxIYIO77wAIQuBcEicOzTKzWQBm9hkze93M5pjZ74Lxa9rH3r85GH//TTMbH8z/kpktMLN5\nZvZyZv40ka5pS0GkE8GP+6tAEYmzSR9297+Y2UqCLYVg6+EPwOnuvs3M/hnId/frg3a/dPcfmtnF\nwHnufpaZvQOc5u5rzKzE3Tdn5A8U6YK2FEQ64YmB9o4EZgJ1wMPBIHOpjiFxMZTXLHG1rq8AY1Ke\nfzDl/thg+jXgV2b2dyQukCLSr+RkugCR/srd24CXgJeC/+F/pUMTA5539wu6eomO0+5+mZkdDZwJ\nvG1mR7p7Xw7iJ7Jb2lIQ6YQlrhF9UMqsKcAqYAuJSyZCYhC+41OOFwwys4NTlvnblPvXgzbj3P0N\nd7+WxBZI6rDHIhmnLQWRzg0GbrXERe9jJEYenUliKO9nzGytu58U7FJ60Mzyg+W+T2LESoBhZjYf\n2BEsB/BfQdgYiREw5/XJXyOSJh1oFglB6gHpTNcisje0+0hERJK0pSAiIknaUhARkSSFgoiIJCkU\nREQkSaEgIiJJCgUREUlSKIiISNL/Abkyu04ROcjTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0f0679f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "a = [i[0] for i in records]\n",
    "plt.plot(a, label = 'Train Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 [33, 14, 13, 6] [14, 13, 6, 58]\n",
      "Variable containing:\n",
      " 12\n",
      "[torch.LongTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category_input, line_input, line_target = random_training_set()\n",
    "print(category_input,line_input,line_target)\n",
    "\n",
    "category_variable =Variable(torch.LongTensor(np.array([category_input])))\n",
    "print(category_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33, 14, 13, 6]\n",
      "x: Variable containing:\n",
      " 12\n",
      " 33\n",
      "[torch.LongTensor of size 2x1]\n",
      "\n",
      "y: Variable containing:\n",
      " 12\n",
      " 14\n",
      "[torch.LongTensor of size 2]\n",
      "\n",
      "output: Variable containing:\n",
      "\n",
      "Columns 0 to 7 \n",
      " -7.6223 -16.3712  -5.2575  -7.4323 -14.1191 -12.7495  -6.0463  -7.9841\n",
      " -0.9720  -6.2958  -5.9078  -6.7603  -2.3781  -8.6197  -8.6854  -5.8696\n",
      "\n",
      "Columns 8 to 15 \n",
      "-13.1167  -9.3242 -11.9493  -7.2719  -0.0173  -8.6945  -5.8931 -15.2512\n",
      " -2.5721  -9.0082  -9.6383  -5.5788  -7.2735  -7.4884  -1.3644  -5.2803\n",
      "\n",
      "Columns 16 to 23 \n",
      "-13.7072  -5.5850  -9.6204 -10.0998  -9.7830 -11.5185  -9.6959 -11.9997\n",
      " -8.0350  -4.4532  -5.7749  -6.0160  -1.9541  -8.4552  -5.7726 -10.7585\n",
      "\n",
      "Columns 24 to 31 \n",
      "-12.6510 -10.7926 -14.5638  -9.1270 -10.7655 -10.3632 -22.4923 -16.2821\n",
      " -4.4812  -6.8534 -14.5945 -14.0463 -15.9115 -15.9477 -24.3491 -15.9836\n",
      "\n",
      "Columns 32 to 39 \n",
      "-11.7907 -10.3027 -21.7551 -22.4805 -10.0079 -11.2759 -10.5400  -9.9822\n",
      "-15.4044 -15.8451 -23.5043 -24.3488 -14.6396 -15.2765 -15.8740 -14.5124\n",
      "\n",
      "Columns 40 to 47 \n",
      "-18.7455 -16.4313 -22.4932 -11.0103 -11.3857 -11.4640 -22.0709 -22.5495\n",
      "-20.0916 -15.8277 -24.4041 -15.4113 -14.8090 -13.9283 -23.9275 -24.4049\n",
      "\n",
      "Columns 48 to 55 \n",
      "-22.5649 -22.5017 -11.5057 -22.4812 -11.7662 -22.5529 -21.8164 -22.5007\n",
      "-24.4157 -24.4717 -13.1533 -24.4116  -8.0476 -24.4036 -23.5169 -24.4438\n",
      "\n",
      "Columns 56 to 58 \n",
      "-17.8170 -11.1635 -14.3949\n",
      " -6.0342 -11.3352  -8.6593\n",
      "[torch.FloatTensor of size 2x59]\n",
      "\n",
      "\n",
      " output_dist: \n",
      "1.00000e-03 *\n",
      "  7.7509\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0069\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0026\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  1.0893\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0571\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "[torch.FloatTensor of size 59]\n",
      "\n",
      "top_i: 0\n",
      "a\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "x: Variable containing:\n",
      " 12\n",
      " 14\n",
      "[torch.LongTensor of size 2x1]\n",
      "\n",
      "y: Variable containing:\n",
      " 12\n",
      " 13\n",
      "[torch.LongTensor of size 2]\n",
      "\n",
      "output: Variable containing:\n",
      "\n",
      "Columns 0 to 7 \n",
      " -9.8484 -21.6479  -6.7175  -9.2568 -17.9819 -16.4458  -8.1086 -10.9628\n",
      " -3.7190  -3.8813  -3.5973  -3.4396  -3.1877  -4.8013  -4.0024  -5.2023\n",
      "\n",
      "Columns 8 to 15 \n",
      "-17.4344 -11.2084 -15.4250  -9.1383  -0.0035 -11.3049  -7.2729 -19.1732\n",
      " -3.3735  -5.2561  -4.3942  -2.7652  -2.9937  -1.8777  -2.7858  -3.8607\n",
      "\n",
      "Columns 16 to 23 \n",
      "-17.4324  -7.1356 -12.1753 -13.1811 -12.7822 -14.5527 -12.3614 -14.3258\n",
      " -6.6375  -2.2872  -2.6011  -3.4582  -2.7333  -3.6812  -4.0732  -6.9907\n",
      "\n",
      "Columns 24 to 31 \n",
      "-16.0475 -13.7465 -16.4628 -10.1410 -11.8363 -11.4294 -23.9009 -18.2947\n",
      " -3.7885  -4.6344 -14.8312 -13.5196 -16.4278 -16.1359 -29.2842 -17.0814\n",
      "\n",
      "Columns 32 to 39 \n",
      "-13.2224 -11.3683 -23.1856 -23.8724 -11.2256 -12.5969 -11.5495 -11.1336\n",
      "-16.0236 -15.8784 -28.3114 -29.4837 -14.0891 -15.5775 -16.3510 -13.9354\n",
      "\n",
      "Columns 40 to 47 \n",
      "-20.3654 -18.5305 -23.8893 -12.2066 -12.7318 -13.0461 -23.4626 -23.9377\n",
      "-22.6497 -16.8527 -29.4361 -15.5311 -15.4309 -14.4771 -28.9107 -29.5442\n",
      "\n",
      "Columns 48 to 55 \n",
      "-23.9510 -23.8879 -12.8537 -23.8778 -14.2513 -23.9275 -23.2716 -23.8964\n",
      "-29.5162 -29.5469 -15.7299 -29.4876  -6.4270 -29.6345 -27.7614 -29.4312\n",
      "\n",
      "Columns 56 to 58 \n",
      "-21.6193 -12.6709 -17.5237\n",
      "-11.1401 -11.6405  -2.6431\n",
      "[torch.FloatTensor of size 2x59]\n",
      "\n",
      "\n",
      " output_dist: \n",
      "1.00000e-05 *\n",
      "  0.0008\n",
      "  0.0004\n",
      "  0.0015\n",
      "  0.0034\n",
      "  0.0120\n",
      "  0.0000\n",
      "  0.0002\n",
      "  0.0000\n",
      "  0.0047\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0989\n",
      "  0.0316\n",
      "  8.3679\n",
      "  0.0893\n",
      "  0.0004\n",
      "  0.0000\n",
      "  1.0799\n",
      "  0.2248\n",
      "  0.0031\n",
      "  0.1161\n",
      "  0.0010\n",
      "  0.0001\n",
      "  0.0000\n",
      "  0.0006\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.1823\n",
      "[torch.FloatTensor of size 59]\n",
      "\n",
      "top_i: 13\n",
      "n\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "x: Variable containing:\n",
      " 12\n",
      " 13\n",
      "[torch.LongTensor of size 2x1]\n",
      "\n",
      "y: Variable containing:\n",
      " 12\n",
      "  6\n",
      "[torch.LongTensor of size 2]\n",
      "\n",
      "output: Variable containing:\n",
      "\n",
      "Columns 0 to 7 \n",
      "-10.1132 -22.5432  -6.9783  -9.3914 -18.6288 -16.8539  -8.3305 -11.2952\n",
      " -3.2818  -5.7059  -4.0053  -2.5401  -2.8539  -4.3284  -1.4368  -4.4980\n",
      "\n",
      "Columns 8 to 15 \n",
      "-18.1749 -11.3362 -16.0763  -9.4403  -0.0028 -11.8083  -7.4399 -19.7961\n",
      " -3.9043  -5.2345  -3.8715  -4.7489  -3.7370  -2.9453  -3.3979  -6.1179\n",
      "\n",
      "Columns 16 to 23 \n",
      "-17.7172  -7.2461 -12.4389 -13.6253 -13.3423 -14.9741 -12.7798 -14.5385\n",
      " -8.3525  -6.1223  -3.4481  -2.6818  -6.0232  -6.1723  -7.1689  -7.6865\n",
      "\n",
      "Columns 24 to 31 \n",
      "-16.5781 -14.1671 -16.6672 -10.2388 -11.9071 -11.4836 -24.0957 -18.5318\n",
      " -5.3841  -5.2731 -14.8088 -13.0912 -16.1658 -15.7097 -28.5508 -16.6106\n",
      "\n",
      "Columns 32 to 39 \n",
      "-13.3625 -11.4262 -23.3826 -24.0657 -11.3387 -12.7116 -11.6070 -11.2504\n",
      "-15.7894 -15.4293 -27.6152 -28.6834 -14.0546 -15.5056 -16.0907 -13.5235\n",
      "\n",
      "Columns 40 to 47 \n",
      "-20.5725 -18.7841 -24.0835 -12.2997 -12.8803 -13.2517 -23.6553 -24.1282\n",
      "-22.2584 -16.4106 -28.6622 -15.4788 -15.4669 -14.3619 -28.1727 -28.7496\n",
      "\n",
      "Columns 48 to 55 \n",
      "-24.1373 -24.0791 -13.0862 -24.0728 -14.5257 -24.1138 -23.4648 -24.0879\n",
      "-28.6869 -28.7054 -17.3247 -28.6793  -5.8040 -28.7881 -27.0809 -28.6097\n",
      "\n",
      "Columns 56 to 58 \n",
      "-22.0021 -12.8033 -17.7347\n",
      "-11.4931 -12.1935  -1.3695\n",
      "[torch.FloatTensor of size 2x59]\n",
      "\n",
      "\n",
      " output_dist: \n",
      "1.00000e-03 *\n",
      "  0.0001\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0030\n",
      "  0.0006\n",
      "  0.0000\n",
      "  0.7586\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0004\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0015\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  0.0000\n",
      "  1.0619\n",
      "[torch.FloatTensor of size 59]\n",
      "\n",
      "top_i: 58\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-7355492bf383>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"top_i:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtop_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# 继续下一个字符\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mchar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_letters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "hidden=lstm.initHidden()\n",
    "print(line_input)\n",
    "for t in range(len(line_input)):\n",
    "        # 姓氏\n",
    "        name_variable = Variable(torch.LongTensor([line_input[t]]).unsqueeze(0))\n",
    "        x= torch.cat((category_variable,name_variable), )\n",
    "        print(\"x:\",x)\n",
    "        # 目标\n",
    "        y_target=Variable(torch.LongTensor([line_target[t]]))\n",
    "        y=torch.cat((category_variable,y_target),)\n",
    "        print(\"y:\",y)\n",
    "        output,hidden=lstm(x,hidden)\n",
    "        print(\"output:\",output)\n",
    "        #将输出转化成一个多项式分布\n",
    "        output_dist = output.data[1].view(-1).div(0.2).exp()\n",
    "        print(\"\\n output_dist:\",output_dist)\n",
    "        # 从而可以根据混乱度 temperature 来选择下一个字符\n",
    "        # 混乱度低，则趋向于选择网络预测最大概率的那个字符\n",
    "        # 混乱度高，则趋向于随机选择字符\n",
    "        top_i = torch.multinomial(output_dist,1)[0]\n",
    "        print(\"top_i:\",top_i)\n",
    "        # 继续下一个字符\n",
    "        char = all_letters[top_i]\n",
    "        print(char)\n",
    "        print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试使用神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然神经网络训练好了，那也就是说，我们喂给它第一个字符，他就能生成第二个字符，喂给它第二个字符，它就会生成第三个，这样一直持续下去，直至生成 EOS 才结束。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那下面我们编写 `generate_one` 函数以方便的使用神经网络生成我们想要的名字字符串，在这个函数里我们定义以下内容：\n",
    "\n",
    "* 建立输入国别，开始字符，初始隐藏层状态的 Tensor\n",
    "* 创建 `output_str` 变量，创建时其中只包含“开始字符”\n",
    "* 定义生成名字的长度最大不超过 `max_length`\n",
    "    * 将当前字符传入神经网络\n",
    "    * 在输出中选出预测的概率最大的下一个字符，同时取出当前的隐藏层状态\n",
    "    * 如果字符是 EOS，则生成结束\n",
    "    * 如果是常规字符，则加入到 `output_str` 中并继续下一个流程\n",
    "* 返回最终生成的名字字符串"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 你需要自行编写模型验证方法。 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_length = 20\n",
    "\n",
    "# 通过指定国别名 category\n",
    "# 以及开始字符 start_char\n",
    "# 还有混乱度 temperature 来生成一个名字\n",
    "def generate_one(category, start_char='A', temperature=0.2):\n",
    "    # 初始化输入数据，国别 以及 输入的第一个字符\n",
    "    # 国别\n",
    "    category_index=make_category_input(category)#将国别索引成序号\n",
    "    category_variable =Variable(torch.LongTensor(np.array([category_index])))#将编码转换成variable形式\n",
    "    # 第一个字符\n",
    "    chars_input=make_chars_input(start_char)#将字符进行编码\n",
    "    #将编码转换成variable形式\n",
    "    name_variable=Variable(torch.LongTensor([chars_input]))\n",
    "    #将国别和第一个字符的variable形式合并，并以input形式喂给lstm forward\n",
    "    input=torch.cat((category_variable,name_variable), )\n",
    "    # 初始化隐藏层\n",
    "    hidden=lstm.initHidden()\n",
    "\n",
    "    output_str = start_char\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        \n",
    "        # 调用模型\n",
    "        output, hidden = lstm(input,hidden)\n",
    "        # 这里是将输出转化为一个多项式分布\n",
    "        #!!!!!!!output是2×59形式的张量，第一行代表国别，第二行才代表字符，如果默认取第一行的话，\n",
    "        #output_dist的维度是2×59=118,很大部分是国别的编码，这样生成的字符的编码很大概率是国别的编码\n",
    "        output_dist = output.data[1].view(-1).div(temperature).exp()\n",
    "        # 从而可以根据混乱度 temperature 来选择下一个字符\n",
    "        # 混乱度低，则趋向于选择网络预测最大概率的那个字符\n",
    "        # 混乱度高，则趋向于随机选择字符\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # 生成字符是 EOS，则生成结束\n",
    "        if top_i == EOS:\n",
    "            break\n",
    "        else:\n",
    "            # 继续下一个字符\n",
    "            char = all_letters[top_i]\n",
    "            output_str += char\n",
    "            chars_input = make_chars_input(char)\n",
    "            name_variable = Variable(torch.LongTensor([chars_input]))\n",
    "            input=torch.cat((category_variable,name_variable), )# 为了循环，输出的生成字符作为下一个循环的输入\n",
    "            \n",
    "    return output_str\n",
    "\n",
    "# 再定义一个函数，方便每次生成多个名字\n",
    "def generate(category, start_chars='a'):\n",
    "    for start_char in start_chars:\n",
    "        print(generate_one(category, start_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "San\n",
      "Para\n",
      "Nas\n"
     ]
    }
   ],
   "source": [
    "generate('Spanish', 'SPN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rig\n",
      "Ung\n",
      "san\n"
     ]
    }
   ],
   "source": [
    "generate('Russian', 'RUs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "san\n",
      "ppppppppppppppppppppp\n",
      "Sara\n"
     ]
    }
   ],
   "source": [
    "generate('Spanish', 'spS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sau\n",
      "Pang\n",
      "Alan\n"
     ]
    }
   ],
   "source": [
    "generate('Spanish', 'SPA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chin\n",
      "hhhhhhhhhhhhhhhhhhhhh\n",
      "iiiiiiiiiiiiiiiiiiiii\n"
     ]
    }
   ],
   "source": [
    "generate('Chinese', 'Chi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cher\n",
      "Han\n",
      "Irar\n"
     ]
    }
   ],
   "source": [
    "generate('Chinese','CHI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mara'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_one('Chinese','M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Macha'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_one('Korean','M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 LSTM 预测的效果，但显然还不理想，我想你可以通过调整网络模型，或者通过调整超参数让模型表现的更好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://wiki.swarma.net/images/c/ca/AI学园.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "nbpresent": {
   "slides": {
    "10393c05-7962-4245-9228-8b7db4eb79a1": {
     "id": "10393c05-7962-4245-9228-8b7db4eb79a1",
     "prev": "22628fc4-8309-4579-ba36-e5b01a841473",
     "regions": {
      "335fd672-4ee6-4b7c-a65f-3ecbf38305e1": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cc294dae-dd8f-4288-8d3c-bb9fd3ad19bc",
        "part": "whole"
       },
       "id": "335fd672-4ee6-4b7c-a65f-3ecbf38305e1"
      }
     }
    },
    "22628fc4-8309-4579-ba36-e5b01a841473": {
     "id": "22628fc4-8309-4579-ba36-e5b01a841473",
     "prev": null,
     "regions": {
      "6cfa5157-02f6-48e3-8ce4-89641febbe59": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9a73330c-27c1-4957-8e95-c3b42bc14a71",
        "part": "whole"
       },
       "id": "6cfa5157-02f6-48e3-8ce4-89641febbe59"
      }
     }
    },
    "2f34f0df-3ccc-4416-9d5d-cb4b075f539f": {
     "id": "2f34f0df-3ccc-4416-9d5d-cb4b075f539f",
     "prev": "3eb7f63f-04de-4f51-a240-38d5074bed6f",
     "regions": {
      "e25707b9-630e-4ece-9f66-bfcbc8342d76": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "df50f546-6d02-4383-beab-90378f16576b",
        "part": "whole"
       },
       "id": "e25707b9-630e-4ece-9f66-bfcbc8342d76"
      }
     }
    },
    "3eb7f63f-04de-4f51-a240-38d5074bed6f": {
     "id": "3eb7f63f-04de-4f51-a240-38d5074bed6f",
     "prev": "cc4bd43a-59ec-4127-b1d8-ebd30162207a",
     "regions": {
      "76282c28-a6ba-4a08-be6c-4f27f5b81ddf": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "53fb987f-4f42-4bf8-81ae-280ebdd19aee",
        "part": "whole"
       },
       "id": "76282c28-a6ba-4a08-be6c-4f27f5b81ddf"
      }
     }
    },
    "686bcaec-0623-4943-b227-f4e1c5975c4a": {
     "id": "686bcaec-0623-4943-b227-f4e1c5975c4a",
     "prev": "e4c6fc30-f833-4368-99fe-5297b99f1f14",
     "regions": {
      "659c021e-7f79-4612-aa7d-8f1c48f91f8b": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4ff5f52a-2523-47f0-beba-f6c29d412e5f",
        "part": "whole"
       },
       "id": "659c021e-7f79-4612-aa7d-8f1c48f91f8b"
      }
     }
    },
    "964ac1b6-c781-47e8-89f0-1f593d473cd0": {
     "id": "964ac1b6-c781-47e8-89f0-1f593d473cd0",
     "prev": "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8",
     "regions": {
      "d22afc7e-4bbe-401e-9bd2-d12c4a103cf5": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "8ff6da45-57cd-46ca-b14a-3f560ce4d345",
        "part": "whole"
       },
       "id": "d22afc7e-4bbe-401e-9bd2-d12c4a103cf5"
      }
     }
    },
    "cc4bd43a-59ec-4127-b1d8-ebd30162207a": {
     "id": "cc4bd43a-59ec-4127-b1d8-ebd30162207a",
     "prev": "964ac1b6-c781-47e8-89f0-1f593d473cd0",
     "regions": {
      "1e6711af-7711-4579-ac7a-f893b0d86931": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cf311809-10bf-40f7-87e1-1952342f7f35",
        "part": "whole"
       },
       "id": "1e6711af-7711-4579-ac7a-f893b0d86931"
      }
     }
    },
    "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8": {
     "id": "cf8a3b4c-bbb5-4ef3-a8c6-43a1ad7eebc8",
     "prev": "686bcaec-0623-4943-b227-f4e1c5975c4a",
     "regions": {
      "3b983e72-35fb-4d19-83b4-789a3394f61f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "597a765d-634b-41a8-a0c6-be5c019da150",
        "part": "whole"
       },
       "id": "3b983e72-35fb-4d19-83b4-789a3394f61f"
      }
     }
    },
    "e4c6fc30-f833-4368-99fe-5297b99f1f14": {
     "id": "e4c6fc30-f833-4368-99fe-5297b99f1f14",
     "prev": "10393c05-7962-4245-9228-8b7db4eb79a1",
     "regions": {
      "98a6b3b6-d2db-4d8a-bb16-a4307ede4803": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6a9d80df-1d38-4c41-849c-95e38da98cc7",
        "part": "whole"
       },
       "id": "98a6b3b6-d2db-4d8a-bb16-a4307ede4803"
      }
     }
    },
    "f1a487d8-4b0b-47df-988f-1161d66174b2": {
     "id": "f1a487d8-4b0b-47df-988f-1161d66174b2",
     "prev": "2f34f0df-3ccc-4416-9d5d-cb4b075f539f",
     "regions": {
      "2c817a32-203d-404b-8bf5-ba17f7d27034": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "81fde336-785e-461b-a751-718a5f6bff88",
        "part": "whole"
       },
       "id": "2c817a32-203d-404b-8bf5-ba17f7d27034"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
